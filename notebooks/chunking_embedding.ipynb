{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d560fea",
   "metadata": {},
   "source": [
    "##  import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "870df19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sys\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0eac93",
   "metadata": {},
   "source": [
    "## Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16024072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def create_stratified_sample(input_file, sample_size, stratify_col='Product', random_state=42):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Project\\complaint-chatbot\\data\\raw\\filtered_complaints.csv\")\n",
    "    \n",
    "    # Calculate fraction per group\n",
    "    total_rows = len(df)\n",
    "    frac = sample_size / total_rows\n",
    "    \n",
    "    # Stratified sampling\n",
    "    df_sampled = df.groupby(stratify_col, group_keys=False).apply(\n",
    "        lambda x: x.sample(frac=frac, random_state=random_state)\n",
    "    ).reset_index(drop=True)\n",
    "    \n",
    "    return df_sampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89ef0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load original dataset\n",
    "original_df = pd.read_csv(r\"C:\\Users\\user\\Desktop\\Project\\complaint-chatbot\\data\\processed\\filtered_complaints.csv\")\n",
    "\n",
    "# If sample_df already exists from previous stratified sampling, keep it\n",
    "# Otherwise, create it using your create_stratified_sample function\n",
    "\n",
    "# Count product occurrences\n",
    "original_counts = original_df['Product'].value_counts()\n",
    "sample_counts = sample_df['Product'].value_counts()\n",
    "\n",
    "# Plot side-by-side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Original dataset\n",
    "axes[0].bar(range(len(original_counts)), original_counts.values)\n",
    "axes[0].set_xticks(range(len(original_counts)))\n",
    "axes[0].set_xticklabels(original_counts.index, rotation=45, ha='right')\n",
    "axes[0].set_title('Original Dataset - Product Distribution')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Sample dataset\n",
    "axes[1].bar(range(len(sample_counts)), sample_counts.values, color='orange')\n",
    "axes[1].set_xticks(range(len(sample_counts)))\n",
    "axes[1].set_xticklabels(sample_counts.index, rotation=45, ha='right')\n",
    "axes[1].set_title('Sample Dataset - Product Distribution')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(r'../report/images/sampling_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Proportional representation check\n",
    "print(\"\\nProportional representation check:\")\n",
    "\n",
    "print(\"\\nOriginal proportions (%):\")\n",
    "print((original_df['Product'].value_counts(normalize=True) * 100).round(2))\n",
    "\n",
    "print(\"\\nSample proportions (%):\")\n",
    "print((sample_df['Product'].value_counts(normalize=True) * 100).round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8451679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chunking import create_text_chunks, analyze_chunks, save_chunks\n",
    "\n",
    "# Create text chunks\n",
    "chunks_data = create_text_chunks(\n",
    "    df=sample_df,\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50,\n",
    "    text_column=\"Consumer complaint narrative\"\n",
    ")\n",
    "\n",
    "# Analyze chunks\n",
    "analyze_chunks(chunks_data)\n",
    "\n",
    "# Save chunks\n",
    "save_chunks(chunks_data, r\"C:\\Users\\user\\Desktop\\Project\\complaint-chatbot\\data\\processed\\chunck_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ca9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize chunk statistics\n",
    "chunk_lengths = [len(chunk['text']) for chunk in chunks_data]\n",
    "chunks_per_complaint = {}\n",
    "for chunk in chunks_data:\n",
    "    cid = chunk['complaint_id']\n",
    "    chunks_per_complaint[cid] = chunk['total_chunks']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Chunk length distribution\n",
    "axes[0].hist(chunk_lengths, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0].axvline(np.mean(chunk_lengths), color='red', linestyle='--', label=f'Mean: {np.mean(chunk_lengths):.0f}')\n",
    "axes[0].axvline(np.median(chunk_lengths), color='green', linestyle='--', label=f'Median: {np.median(chunk_lengths):.0f}')\n",
    "axes[0].set_xlabel('Chunk Length (characters)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Chunk Lengths')\n",
    "axes[0].legend()\n",
    "\n",
    "# Chunks per complaint distribution\n",
    "chunks_counts = list(chunks_per_complaint.values())\n",
    "axes[1].hist(chunks_counts, bins=range(1, max(chunks_counts)+2), edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1].axvline(np.mean(chunks_counts), color='red', linestyle='--', label=f'Mean: {np.mean(chunks_counts):.2f}')\n",
    "axes[1].set_xlabel('Chunks per Complaint')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Chunks per Complaint')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../report/images/chunking_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8664ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from embedding import generate_embeddings, analyze_embeddings, save_embeddings\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings, chunks_df = generate_embeddings(\n",
    "    chunks_file=r\"C:\\Users\\user\\Desktop\\Project\\complaint-chatbot\\data\\processed\\chunck_sample.csv\",\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Analyze embeddings\n",
    "analyze_embeddings(embeddings)\n",
    "\n",
    "# Save embeddings\n",
    "save_embeddings(embeddings, chunks_df, r\"C:\\Users\\user\\Desktop\\Project\\complaint-chatbot\\data\\processed\\sample_embedding.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f91fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embedding statistics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Embedding value distribution\n",
    "axes[0].hist(embeddings.flatten(), bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[0].set_xlabel('Embedding Value')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Embedding Values')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Embedding norms\n",
    "norms = np.linalg.norm(embeddings, axis=1)\n",
    "axes[1].hist(norms, bins=50, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1].axvline(np.mean(norms), color='red', linestyle='--', label=f'Mean: {np.mean(norms):.4f}')\n",
    "axes[1].set_xlabel('L2 Norm')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Embedding Norms')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../report/images/embedding_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef155d",
   "metadata": {},
   "source": [
    "##  FAISS Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_store_builder import build_vector_store, test_vector_store\n",
    "\n",
    "# Build vector store\n",
    "store = build_vector_store(\n",
    "    embeddings_file=\"../data/processed/sample_embeddings.npy\",\n",
    "    metadata_file=\"../data/processed/sample_chunks.csv\",\n",
    "    output_dir=\"../vector_store/faiss_index\",\n",
    "    index_type=\"flat\"\n",
    ")\n",
    "\n",
    "# Test vector store\n",
    "test_vector_store(store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7a5ce0",
   "metadata": {},
   "source": [
    "##  Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeade9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_store_builder import FAISSVectorStore\n",
    "\n",
    "# Load the vector store\n",
    "store = FAISSVectorStore.load(\"../vector_store/faiss_index\")\n",
    "store.load_model()\n",
    "\n",
    "# Custom query\n",
    "query = \"I want to dispute fraudulent charges on my account\"\n",
    "results = store.query(query, k=5)\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(f\"  Similarity: {result['similarity']:.4f}\")\n",
    "    print(f\"  Product: {result.get('product_category', 'N/A')}\")\n",
    "    print(f\"  Issue: {result.get('issue', 'N/A')}\")\n",
    "    print(f\"  Company: {result.get('company', 'N/A')}\")\n",
    "    print(f\"  State: {result.get('state', 'N/A')}\")\n",
    "    print(f\"  Text: {result.get('text', '')[:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b0552c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with metadata filtering\n",
    "query = \"problems with online banking\"\n",
    "results = store.query(query, k=5, filter_metadata={'product_category': 'Checking or savings account'})\n",
    "\n",
    "print(f\"Query: '{query}'\")\n",
    "print(f\"Filter: Product = 'Checking or savings account'\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(f\"  Similarity: {result['similarity']:.4f}\")\n",
    "    print(f\"  Product: {result.get('product_category', 'N/A')}\")\n",
    "    print(f\"  Issue: {result.get('issue', 'N/A')}\")\n",
    "    print(f\"  Text: {result.get('text', '')[:200]}...\")\n",
    "    print(\"-\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
